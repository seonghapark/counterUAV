{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUAV_Model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.n_hidden = 40\n",
    "        pass\n",
    "\n",
    "    def windows(self, data, window_size):\n",
    "        start = 0\n",
    "        while start < len(data):\n",
    "            yield start, start + window_size\n",
    "            start += (window_size / 2)\n",
    "\n",
    "    # 각 33개 input, 각 6개 label\n",
    "\n",
    "    def extract_features(self, file_path, file_label, file_ext=\"*.wav\",bands = 20, frames = 41):\n",
    "        window_size = 512 * (frames - 1)\n",
    "        mfccs = []\n",
    "        log_specgrams = []\n",
    "        features = []\n",
    "        labels = []\n",
    "        sound_clip, s = librosa.load(file_path)\n",
    "        #print(type(sound_clip))\n",
    "        if file_label=='other':\n",
    "            label_code = 0\n",
    "        elif file_label=='person':\n",
    "            label_code = 1\n",
    "        elif file_label=='car':\n",
    "            label_code = 2\n",
    "        elif file_label=='drone':\n",
    "            label_code = 3\n",
    "\n",
    "        #print(file_label, label_code)\n",
    "        for (start,end) in self.windows(sound_clip,window_size):\n",
    "            start = int(start)\n",
    "            end = int(end)\n",
    "            if(len(sound_clip[start:end]) == window_size):\n",
    "                signal = sound_clip[start:end]\n",
    "\n",
    "                melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "                logspec = librosa.amplitude_to_db(melspec)\n",
    "                logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                #print(1, logspec.shape)\n",
    "                log_specgrams.append(logspec)\n",
    "\n",
    "                mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
    "                mfccs.append(mfcc)\n",
    "                #print(2, mfcc.shape)\n",
    "                features = np.hstack((mfccs, log_specgrams))\n",
    "                labels.append(label_code)         \n",
    "        features = np.asarray(features).reshape(len(mfccs), frames, bands*2)\n",
    "        #print(features.shape)\n",
    "        return np.array(features), np.array(labels,dtype = np.int)\n",
    "\n",
    "    def extract_features_for_predict(self, file_path, bands = 20, frames = 41):\n",
    "        window_size = 512 * (frames - 1)\n",
    "        mfccs = []\n",
    "        log_specgrams = []\n",
    "        features = []\n",
    "        sound_clip, s = librosa.load(file_path)\n",
    "\n",
    "        for (start,end) in self.windows(sound_clip,window_size):\n",
    "            start = int(start)\n",
    "            end = int(end)\n",
    "            if(len(sound_clip[start:end]) == window_size):\n",
    "                signal = sound_clip[start:end]\n",
    "\n",
    "                melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "                logspec = librosa.amplitude_to_db(melspec)\n",
    "                logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                log_specgrams.append(logspec)\n",
    "\n",
    "                mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
    "                mfccs.append(mfcc)\n",
    "                features = np.hstack((mfccs, log_specgrams))      \n",
    "\n",
    "        features = np.asarray(features).reshape(len(mfccs), frames, bands*2)\n",
    "        #print(features.shape)\n",
    "        return np.array(features)\n",
    "\n",
    "    def one_hot_encode(self, labels):\n",
    "        n_labels = len(labels)\n",
    "        n_unique_labels = len(np.unique(labels))\n",
    "        one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "        one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "        return one_hot_encode\n",
    "    \n",
    "    def make_data(self):\n",
    "        wav_file_path_training = 'C://slice_wav_data/training/'\n",
    "        file_list_training = os.listdir(wav_file_path_training)\n",
    "\n",
    "        tr_features = []\n",
    "        tr_labels = []\n",
    "        for f in file_list_training:\n",
    "            file_label = f.split(\"_\")[0]\n",
    "            #if file_label=='person' or file_label=='car': ## 2개씩만 하는 코드\n",
    "             #   continue\n",
    "            features_temp, labels_temp = self.extract_features(wav_file_path_training + f, file_label)\n",
    "            for tr_f in features_temp:\n",
    "                tr_features.append(tr_f)\n",
    "            for tr_l in labels_temp:\n",
    "                tr_labels.append(tr_l)\n",
    "\n",
    "\n",
    "        tmp = [[x,y] for x,y in zip(tr_features, tr_labels)]\n",
    "        random.shuffle(tmp)\n",
    "        tr_features = [n[0] for n in tmp]\n",
    "        tr_labels = [n[1] for n in tmp]\n",
    "\n",
    "\n",
    "        wav_file_path_test = 'C://slice_wav_data/testing/'\n",
    "        file_list_test = os.listdir(wav_file_path_test)\n",
    "\n",
    "        ts_features = []\n",
    "        ts_labels = []\n",
    "        for f in file_list_test:\n",
    "            file_label = f.split(\"_\")[0]\n",
    "            #if file_label=='person' or file_label=='car': ## 2개씩만 하는 코드\n",
    "             #   continue\n",
    "            features_temp, labels_temp = self.extract_features(wav_file_path_test + f, file_label)\n",
    "            for ts_f in features_temp:\n",
    "                ts_features.append(ts_f)\n",
    "            for ts_l in labels_temp:\n",
    "                ts_labels.append(ts_l)\n",
    "\n",
    "        tr_labels = self.one_hot_encode(tr_labels)\n",
    "        ts_labels = self.one_hot_encode(ts_labels)\n",
    "\n",
    "        self.tr_features = np.array(tr_features)\n",
    "        self.tr_labels = np.array(tr_labels)\n",
    "\n",
    "        self.ts_features = np.array(ts_features)\n",
    "        self.ts_labels = np.array(ts_labels)\n",
    "        \n",
    "        \n",
    "    def RNN(self, x, weight, bias):\n",
    "        cell = rnn_cell.LSTMCell(self.n_hidden,state_is_tuple = True)\n",
    "        cell = rnn_cell.MultiRNNCell([cell] * 8, state_is_tuple=True)\n",
    "        output, state = tf.nn.dynamic_rnn(cell, x, dtype = tf.float32)\n",
    "        output = tf.transpose(output, [1, 0, 2])\n",
    "        last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "        return tf.nn.softmax(tf.matmul(last, weight) + bias)\n",
    "    \n",
    "    def graph_setting(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.session = tf.Session()\n",
    "\n",
    "        learning_rate = 0.0003\n",
    "\n",
    "        # Network Parameters\n",
    "        n_input = 40\n",
    "        n_steps = 41\n",
    "        n_classes = 4\n",
    "\n",
    "        #앞에거는 hidden *2, 뒤에거는 n_input + n_hidden\n",
    "\n",
    "        self.x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "        self.y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "        weight = tf.Variable(tf.random_normal([self.n_hidden, n_classes]))\n",
    "        bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "        \n",
    "        self.prediction = self.RNN(self.x, weight, bias)\n",
    "        self.prediction_str = tf.argmax(self.prediction, 1)\n",
    "        #prediction_str, prediction, x, \n",
    "        # Define loss and optimizer\n",
    "        self.loss_f = -tf.reduce_sum(self.y * tf.log(self.prediction))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(self.loss_f)\n",
    "\n",
    "        # Evaluate model\n",
    "        self.correct_pred = tf.equal(tf.argmax(self.prediction,1), tf.argmax(self.y,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
    "\n",
    "        # Initializing the variables\n",
    "        \n",
    "    def training(self):\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.session.run(init)\n",
    "\n",
    "        training_epochs = 10000\n",
    "        batch_size = 54 #1188과 216의 최대공약수는 54\n",
    "        \n",
    "        for epoch in range(training_epochs):\n",
    "            avg_cost = 0\n",
    "            total_batch = int(len(self.tr_features) / batch_size)\n",
    "\n",
    "            for i in range(total_batch):\n",
    "                start = ((i+1) * batch_size) - batch_size\n",
    "                end = ((i+1) * batch_size)\n",
    "                batch_x = self.tr_features[start:end]\n",
    "                batch_y = self.tr_labels[start:end]\n",
    "\n",
    "                _, c = self.session.run([self.optimizer, self.loss_f], feed_dict={self.x: batch_x, self.y : batch_y})\n",
    "                avg_cost += c / total_batch\n",
    "\n",
    "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), end='')\n",
    "            print('Test accuracy: ',round(self.session.run(self.accuracy, feed_dict={self.x: self.ts_features, self.y: self.ts_labels}) , 3))\n",
    "            if epoch % 100 == 0:\n",
    "                self.save_network(epoch)\n",
    "        \n",
    "        print('Learning Finished!')\n",
    "\n",
    "        \n",
    "    def save_network(self, step):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(self.session, './rnn_graph_save_3/cuav_rnn.ckpt', step)\n",
    "        print('Graph Saved! ')\n",
    "        \n",
    "        \n",
    "    def predict(self, file_source):\n",
    "        print(file_source)\n",
    "        data_label = file_source.split('/')[-1].split('_')[0]\n",
    "        data_to_predict = self.extract_features_for_predict(file_source)\n",
    "        print(data_to_predict.shape)\n",
    "        result_list = self.session.run(self.prediction_str, feed_dict={self.x: data_to_predict})\n",
    "        print(result_list)\n",
    "        result_list = list(result_list)\n",
    "        label_count = {'others': 0, 'person': 0, 'car': 0, 'drone': 0,}\n",
    "\n",
    "        total = 0\n",
    "        for i, key in enumerate(list(label_count.keys())):\n",
    "            label_count[key] = (result_list.count(i))\n",
    "            print(key, int(label_count[key])/data_to_predict.shape[0])\n",
    "\n",
    "        t = list(zip(list(label_count.values()), list(label_count.keys())))\n",
    "        t.sort(reverse=True)\n",
    "        print(t)\n",
    "        print(\"\")\n",
    "        return t[0][1]\n",
    "        #print(t[0][1][:-1])\n",
    "        #if t[0][1] == data_label or t[0][1][:-1] == data_label:\n",
    "        #    return True, data_label\n",
    "        #else :\n",
    "        #    return False, data_label\n",
    "\n",
    "        #for i in range(data_to_predict.shape[0]):\n",
    "            #temp_output = session.run(prediction, feed_dict={x: data_to_predict[i]})\n",
    "            #print(temp_output)\n",
    "        \n",
    "    def restore_graph(self, step):\n",
    "        save_file = './rnn_graph_save_3/cuav_rnn.ckpt' + '-' + str(step)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(self.session, save_file)\n",
    "        \n",
    "\n",
    "        #sess = tf.InteractiveSession()\n",
    "        #saver = tf.train.import_meta_graph('./cuav_rnn.ckpt.meta')\n",
    "        #saver.restore(self.sess,'./cuav_rnn.ckpt.ckpt')\n",
    "\n",
    "        #graph = tf.get_default_graph()\n",
    "        #self.X =  self.sess.graph.get_tensor_by_name(\"Placeholder:0\")\n",
    "        #self.Y =  self.sess.graph.get_tensor_by_name(\"Placeholder_1:0\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = CUAV_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kvlks\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-2fd54d8fab96>:136: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-4-2fd54d8fab96>:137: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n",
      "WARNING:tensorflow:From <ipython-input-4-2fd54d8fab96>:138: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\kvlks\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kvlks\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "m1.graph_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b8dd15c61ecc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'm1' is not defined"
     ]
    }
   ],
   "source": [
    "m1.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kvlks\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./rnn_graph_save_3/cuav_rnn.ckpt-1200\n"
     ]
    }
   ],
   "source": [
    "m1.graph_setting()\n",
    "m1.restore_graph(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car_116.wav', 'car_118.wav', 'car_120.wav', 'car_1944.wav', 'car_2242.wav', 'car_2542.wav', 'drone_122.wav', 'drone_128.wav', 'drone_222.wav', 'drone_722.wav', 'drone_822.wav', 'drone_922.wav', 'other_027.wav', 'other_035.wav', 'other_40.wav', 'other_423.wav', 'other_425.wav', 'other_429.wav', 'person_1741.wav', 'person_1941.wav', 'person_2141.wav', 'person_615.wav', 'person_633.wav', 'person_641.wav']\n"
     ]
    }
   ],
   "source": [
    "wav_file_path_test = 'C://slice_wav_data/testing/'\n",
    "test_file_list = os.listdir(wav_file_path_test)\n",
    "print(test_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'car', 'car', 'car', 'car', 'car', 'drone', 'drone', 'drone', 'drone', 'drone', 'drone', 'other', 'other', 'other', 'other', 'other', 'other', 'person', 'person', 'person', 'person', 'person', 'person']\n"
     ]
    }
   ],
   "source": [
    "test_label_list = []\n",
    "for file in test_file_list:\n",
    "    test_label_list.append(file.split('_')[0])\n",
    "print(test_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5e9c320c6938>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mresult_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_file_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtemp_tf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav_file_path_test\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresult_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_file_list' is not defined"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "for file in test_file_list:\n",
    "    temp_tf = m1.predict(wav_file_path_test + file)\n",
    "    result_list.append(temp_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car',\n",
       " 'car',\n",
       " 'person',\n",
       " 'car',\n",
       " 'car',\n",
       " 'car',\n",
       " 'drone',\n",
       " 'drone',\n",
       " 'drone',\n",
       " 'drone',\n",
       " 'drone',\n",
       " 'drone',\n",
       " 'drone',\n",
       " 'others',\n",
       " 'others',\n",
       " 'others',\n",
       " 'others',\n",
       " 'others',\n",
       " 'person',\n",
       " 'person',\n",
       " 'others',\n",
       " 'person',\n",
       " 'person',\n",
       " 'person']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count = 0\n",
    "for i in range(len(result_list)):\n",
    "    if result_list[i] == test_label_list[i] or result_list[i][:-1] == test_label_list[i]:\n",
    "        true_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_count/(len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tf.count(True)/len(result_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./rnn_graph_save_3/cuav_rnn.ckpt-500\n",
      "C://slice_wav_data/testing/car_116.wav\n",
      "(9, 41, 40)\n",
      "[2 2 2 2 2 2 2 2 2]\n",
      "others 0.0\n",
      "person 0.0\n",
      "car 1.0\n",
      "drone 0.0\n",
      "[(9, 'car'), (0, 'person'), (0, 'others'), (0, 'drone')]\n",
      "\n",
      "C://slice_wav_data/testing/car_118.wav\n",
      "(9, 41, 40)\n",
      "[0 2 2 0 0 0 2 2 2]\n",
      "others 0.4444444444444444\n",
      "person 0.0\n",
      "car 0.5555555555555556\n",
      "drone 0.0\n",
      "[(5, 'car'), (4, 'others'), (0, 'person'), (0, 'drone')]\n",
      "\n",
      "C://slice_wav_data/testing/car_120.wav\n",
      "(9, 41, 40)\n",
      "[2 2 2 2 1 1 1 1 1]\n",
      "others 0.0\n",
      "person 0.5555555555555556\n",
      "car 0.4444444444444444\n",
      "drone 0.0\n",
      "[(5, 'person'), (4, 'car'), (0, 'others'), (0, 'drone')]\n",
      "\n",
      "C://slice_wav_data/testing/car_1944.wav\n",
      "(9, 41, 40)\n",
      "[2 2 1 1 2 2 2 0 2]\n",
      "others 0.1111111111111111\n",
      "person 0.2222222222222222\n",
      "car 0.6666666666666666\n",
      "drone 0.0\n",
      "[(6, 'car'), (2, 'person'), (1, 'others'), (0, 'drone')]\n",
      "\n",
      "C://slice_wav_data/testing/car_2242.wav\n",
      "(9, 41, 40)\n",
      "[2 2 2 2 2 2 2 3 3]\n",
      "others 0.0\n",
      "person 0.0\n",
      "car 0.7777777777777778\n",
      "drone 0.2222222222222222\n",
      "[(7, 'car'), (2, 'drone'), (0, 'person'), (0, 'others')]\n",
      "\n",
      "C://slice_wav_data/testing/car_2542.wav\n",
      "(9, 41, 40)\n",
      "[3 3 2 2 2 0 0 2 0]\n",
      "others 0.3333333333333333\n",
      "person 0.0\n",
      "car 0.4444444444444444\n",
      "drone 0.2222222222222222\n",
      "[(4, 'car'), (3, 'others'), (2, 'drone'), (0, 'person')]\n",
      "\n",
      "C://slice_wav_data/testing/drone_122.wav\n",
      "(9, 41, 40)\n",
      "[3 3 3 3 3 3 3 3 3]\n",
      "others 0.0\n",
      "person 0.0\n",
      "car 0.0\n",
      "drone 1.0\n",
      "[(9, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/drone_128.wav\n",
      "(9, 41, 40)\n",
      "[3 3 3 3 3 3 3 3 3]\n",
      "others 0.0\n",
      "person 0.0\n",
      "car 0.0\n",
      "drone 1.0\n",
      "[(9, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/drone_222.wav\n",
      "(9, 41, 40)\n",
      "[3 3 3 3 3 3 3 3 3]\n",
      "others 0.0\n",
      "person 0.0\n",
      "car 0.0\n",
      "drone 1.0\n",
      "[(9, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/drone_722.wav\n",
      "(9, 41, 40)\n",
      "[3 3 3 3 3 3 3 3 3]\n",
      "others 0.0\n",
      "person 0.0\n",
      "car 0.0\n",
      "drone 1.0\n",
      "[(9, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/drone_822.wav\n",
      "(9, 41, 40)\n",
      "[3 3 3 3 3 3 3 3 3]\n",
      "others 0.0\n",
      "person 0.0\n",
      "car 0.0\n",
      "drone 1.0\n",
      "[(9, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/drone_922.wav\n",
      "(9, 41, 40)\n",
      "[3 3 3 3 3 3 3 3 3]\n",
      "others 0.0\n",
      "person 0.0\n",
      "car 0.0\n",
      "drone 1.0\n",
      "[(9, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/other_027.wav\n",
      "(9, 41, 40)\n",
      "[3 3 3 3 3 1 1 3 1]\n",
      "others 0.0\n",
      "person 0.3333333333333333\n",
      "car 0.0\n",
      "drone 0.6666666666666666\n",
      "[(6, 'drone'), (3, 'person'), (0, 'others'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/other_035.wav\n",
      "(9, 41, 40)\n",
      "[2 2 2 2 2 2 0 2 0]\n",
      "others 0.2222222222222222\n",
      "person 0.0\n",
      "car 0.7777777777777778\n",
      "drone 0.0\n",
      "[(7, 'car'), (2, 'others'), (0, 'person'), (0, 'drone')]\n",
      "\n",
      "C://slice_wav_data/testing/other_40.wav\n",
      "(9, 41, 40)\n",
      "[0 0 2 0 0 0 2 0 0]\n",
      "others 0.7777777777777778\n",
      "person 0.0\n",
      "car 0.2222222222222222\n",
      "drone 0.0\n",
      "[(7, 'others'), (2, 'car'), (0, 'person'), (0, 'drone')]\n",
      "\n",
      "C://slice_wav_data/testing/other_423.wav\n",
      "(9, 41, 40)\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "others 1.0\n",
      "person 0.0\n",
      "car 0.0\n",
      "drone 0.0\n",
      "[(9, 'others'), (0, 'person'), (0, 'drone'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/other_425.wav\n",
      "(9, 41, 40)\n",
      "[3 3 3 3 3 0 3 0 0]\n",
      "others 0.3333333333333333\n",
      "person 0.0\n",
      "car 0.0\n",
      "drone 0.6666666666666666\n",
      "[(6, 'drone'), (3, 'others'), (0, 'person'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/other_429.wav\n",
      "(9, 41, 40)\n",
      "[3 3 0 0 0 0 0 0 0]\n",
      "others 0.7777777777777778\n",
      "person 0.0\n",
      "car 0.0\n",
      "drone 0.2222222222222222\n",
      "[(7, 'others'), (2, 'drone'), (0, 'person'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/person_1741.wav\n",
      "(9, 41, 40)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "others 0.0\n",
      "person 1.0\n",
      "car 0.0\n",
      "drone 0.0\n",
      "[(9, 'person'), (0, 'others'), (0, 'drone'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/person_1941.wav\n",
      "(9, 41, 40)\n",
      "[1 1 1 1 1 3 0 0 0]\n",
      "others 0.3333333333333333\n",
      "person 0.5555555555555556\n",
      "car 0.0\n",
      "drone 0.1111111111111111\n",
      "[(5, 'person'), (3, 'others'), (1, 'drone'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/person_2141.wav\n",
      "(9, 41, 40)\n",
      "[3 3 0 0 0 0 0 0 0]\n",
      "others 0.7777777777777778\n",
      "person 0.0\n",
      "car 0.0\n",
      "drone 0.2222222222222222\n",
      "[(7, 'others'), (2, 'drone'), (0, 'person'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/person_615.wav\n",
      "(9, 41, 40)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "others 0.0\n",
      "person 1.0\n",
      "car 0.0\n",
      "drone 0.0\n",
      "[(9, 'person'), (0, 'others'), (0, 'drone'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/person_633.wav\n",
      "(9, 41, 40)\n",
      "[2 2 1 1 1 1 1 1 1]\n",
      "others 0.0\n",
      "person 0.7777777777777778\n",
      "car 0.2222222222222222\n",
      "drone 0.0\n",
      "[(7, 'person'), (2, 'car'), (0, 'others'), (0, 'drone')]\n",
      "\n",
      "C://slice_wav_data/testing/person_641.wav\n",
      "(9, 41, 40)\n",
      "[3 2 1 1 1 1 1 1 1]\n",
      "others 0.0\n",
      "person 0.7777777777777778\n",
      "car 0.1111111111111111\n",
      "drone 0.1111111111111111\n",
      "[(7, 'person'), (1, 'drone'), (1, 'car'), (0, 'others')]\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./rnn_graph_save_3/cuav_rnn.ckpt-600\n",
      "C://slice_wav_data/testing/car_116.wav\n",
      "(9, 41, 40)\n",
      "[2 2 2 2 2 2 2 2 2]\n",
      "others 0.0\n",
      "person 0.0\n",
      "car 1.0\n",
      "drone 0.0\n",
      "[(9, 'car'), (0, 'person'), (0, 'others'), (0, 'drone')]\n",
      "\n",
      
      "car 0.1111111111111111\n",
      "drone 0.0\n",
      "[(5, 'person'), (3, 'others'), (1, 'car'), (0, 'drone')]\n",
      "\n",
      "C://slice_wav_data/testing/person_2141.wav\n",
      "(9, 41, 40)\n",
      "[1 0 0 0 0 0 0 0 0]\n",
      "others 0.8888888888888888\n",
      "person 0.1111111111111111\n",
      "car 0.0\n",
      "drone 0.0\n",
      "[(8, 'others'), (1, 'person'), (0, 'drone'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/person_615.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 41, 40)\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "others 0.0\n",
      "person 1.0\n",
      "car 0.0\n",
      "drone 0.0\n",
      "[(9, 'person'), (0, 'others'), (0, 'drone'), (0, 'car')]\n",
      "\n",
      "C://slice_wav_data/testing/person_633.wav\n",
      "(9, 41, 40)\n",
      "[2 2 2 1 1 1 1 1 1]\n",
      "others 0.0\n",
      "person 0.6666666666666666\n",
      "car 0.3333333333333333\n",
      "drone 0.0\n",
      "[(6, 'person'), (3, 'car'), (0, 'others'), (0, 'drone')]\n",
      "\n",
      "C://slice_wav_data/testing/person_641.wav\n",
      "(9, 41, 40)\n",
      "[2 1 1 1 1 1 1 1 1]\n",
      "others 0.0\n",
      "person 0.8888888888888888\n",
      "car 0.1111111111111111\n",
      "drone 0.0\n",
      "[(8, 'person'), (1, 'car'), (0, 'others'), (0, 'drone')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_result = []\n",
    "for i in range(0,2001,100):\n",
    "    m1.graph_setting()\n",
    "    m1.restore_graph(500+i)\n",
    "    result_temp = []\n",
    "    for file in test_file_list:\n",
    "        temp_ = m1.predict(wav_file_path_test + file)\n",
    "        result_temp.append(temp_)\n",
    "    total_result.append(result_temp) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 24)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_result_np = np.array(total_result)\n",
    "total_result_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'drone', 'car', 'others',\n",
       "        'others', 'drone', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'others', 'others', 'others',\n",
       "        'others', 'others', 'others', 'person', 'others', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'car', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'drone', 'others', 'others',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'drone', 'car', 'car',\n",
       "        'others', 'others', 'others', 'person', 'others', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'car', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'car', 'others',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'drone', 'others', 'others',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'drone', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'others',\n",
       "        'others', 'drone', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'drone', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'car', 'others',\n",
       "        'others', 'drone', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'others',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person'],\n",
       "       ['car', 'car', 'person', 'car', 'car', 'car', 'drone', 'drone',\n",
       "        'drone', 'drone', 'drone', 'drone', 'person', 'others', 'car',\n",
       "        'others', 'others', 'others', 'person', 'person', 'others',\n",
       "        'person', 'person', 'person']], dtype='<U6')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_result_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dict = [{'others': 0, 'person': 0, 'car': 0, 'drone': 0,} for _ in range(len(result_list))]\n",
    "for one_result in total_result:\n",
    "    for i, label in enumerate(one_result):\n",
    "        total_dict[i][label] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'others': 0, 'person': 0, 'car': 21, 'drone': 0},\n",
       " {'others': 0, 'person': 0, 'car': 19, 'drone': 2},\n",
       " {'others': 0, 'person': 21, 'car': 0, 'drone': 0},\n",
       " {'others': 0, 'person': 0, 'car': 21, 'drone': 0},\n",
       " {'others': 0, 'person': 0, 'car': 21, 'drone': 0},\n",
       " {'others': 0, 'person': 0, 'car': 21, 'drone': 0},\n",
       " {'others': 0, 'person': 0, 'car': 0, 'drone': 21},\n",
       " {'others': 0, 'person': 0, 'car': 0, 'drone': 21},\n",
       " {'others': 0, 'person': 0, 'car': 0, 'drone': 21},\n",
       " {'others': 0, 'person': 0, 'car': 0, 'drone': 21},\n",
       " {'others': 0, 'person': 0, 'car': 0, 'drone': 21},\n",
       " {'others': 0, 'person': 0, 'car': 0, 'drone': 21},\n",
       " {'others': 1, 'person': 16, 'car': 0, 'drone': 4},\n",
       " {'others': 15, 'person': 0, 'car': 6, 'drone': 0},\n",
       " {'others': 8, 'person': 0, 'car': 13, 'drone': 0},\n",
       " {'others': 21, 'person': 0, 'car': 0, 'drone': 0},\n",
       " {'others': 18, 'person': 0, 'car': 0, 'drone': 3},\n",
       " {'others': 21, 'person': 0, 'car': 0, 'drone': 0},\n",
       " {'others': 0, 'person': 21, 'car': 0, 'drone': 0},\n",
       " {'others': 2, 'person': 19, 'car': 0, 'drone': 0},\n",
       " {'others': 21, 'person': 0, 'car': 0, 'drone': 0},\n",
       " {'others': 0, 'person': 21, 'car': 0, 'drone': 0},\n",
       " {'others': 0, 'person': 21, 'car': 0, 'drone': 0},\n",
       " {'others': 0, 'person': 21, 'car': 0, 'drone': 0}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_total_dict = []\n",
    "for one_dict in total_dict:\n",
    "    t = list(zip(list(one_dict.values()), list(one_dict.keys())))\n",
    "    t.sort(reverse=True)\n",
    "    sorted_total_dict.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(21, 'car'), (0, 'person'), (0, 'others'), (0, 'drone')],\n",
       " [(19, 'car'), (2, 'drone'), (0, 'person'), (0, 'others')],\n",
       " [(21, 'person'), (0, 'others'), (0, 'drone'), (0, 'car')],\n",
       " [(21, 'car'), (0, 'person'), (0, 'others'), (0, 'drone')],\n",
       " [(21, 'car'), (0, 'person'), (0, 'others'), (0, 'drone')],\n",
       " [(21, 'car'), (0, 'person'), (0, 'others'), (0, 'drone')],\n",
       " [(21, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')],\n",
       " [(21, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')],\n",
       " [(21, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')],\n",
       " [(21, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')],\n",
       " [(21, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')],\n",
       " [(21, 'drone'), (0, 'person'), (0, 'others'), (0, 'car')],\n",
       " [(16, 'person'), (4, 'drone'), (1, 'others'), (0, 'car')],\n",
       " [(15, 'others'), (6, 'car'), (0, 'person'), (0, 'drone')],\n",
       " [(13, 'car'), (8, 'others'), (0, 'person'), (0, 'drone')],\n",
       " [(21, 'others'), (0, 'person'), (0, 'drone'), (0, 'car')],\n",
       " [(18, 'others'), (3, 'drone'), (0, 'person'), (0, 'car')],\n",
       " [(21, 'others'), (0, 'person'), (0, 'drone'), (0, 'car')],\n",
       " [(21, 'person'), (0, 'others'), (0, 'drone'), (0, 'car')],\n",
       " [(19, 'person'), (2, 'others'), (0, 'drone'), (0, 'car')],\n",
       " [(21, 'others'), (0, 'person'), (0, 'drone'), (0, 'car')],\n",
       " [(21, 'person'), (0, 'others'), (0, 'drone'), (0, 'car')],\n",
       " [(21, 'person'), (0, 'others'), (0, 'drone'), (0, 'car')],\n",
       " [(21, 'person'), (0, 'others'), (0, 'drone'), (0, 'car')]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_total_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "car\n",
      "person\n",
      "car\n",
      "car\n",
      "car\n",
      "drone\n",
      "drone\n",
      "drone\n",
      "drone\n",
      "drone\n",
      "drone\n",
      "drone\n",
      "others\n",
      "others\n",
      "others\n",
      "others\n",
      "others\n",
      "person\n",
      "person\n",
      "others\n",
      "person\n",
      "person\n",
      "person\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, labels in enumerate(sorted_total_dict):\n",
    "    print(result_list[i])\n",
    "    if labels[0][1] == result_list[i] or labels[0][1] == result_list[i][:-1]:\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/len(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
